{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве начального набора данных я использую классический бостонский датасет, т.к. он считается хорошим, сложным датасетом и мне интересен результат работы с этим датасетом написанным мною градиентным бустингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4      5     6       7    8      9     10  \\\n",
       "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "\n",
       "       11    12  \n",
       "0  396.90  4.98  \n",
       "1  396.90  9.14  \n",
       "2  392.83  4.03  \n",
       "3  394.63  2.94  \n",
       "4  396.90  5.33  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "pd.DataFrame(data.data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_x, sc_y = StandardScaler(), StandardScaler()\n",
    "\n",
    "X, y = sc_x.fit_transform(X), sc_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "y = y.ravel()\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((379, 13), (379,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написанная мною версия модели ансамблевого обучения для регрессии - градиентного бустинга.\n",
    "\n",
    "В качестве базового оценщика (слабого ученика) я использую простой пень решения (одноуровневое дерево решения), так как в большинстве случаев именно эта модель используется в качестве слабого ученика в этом методе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import clone\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import six\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "class ConstDummyEstimator:\n",
    "    def __init__(self, const):\n",
    "        self.const = np.array(const)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.repeat(self.const, X.shape[0], axis=0)\n",
    "\n",
    "\n",
    "class NewGradientBoost(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, M=10, eta=1):\n",
    "        self.M = M\n",
    "        self.eta = eta\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray, visualize=False):\n",
    "        \n",
    "        if visualize:\n",
    "            fig, ax = plt.subplots(self.M, 2, figsize=(10, 5 * self.M))\n",
    "        \n",
    "        # init with a mean (argmin of MSE)\n",
    "        self.models_ = [ConstDummyEstimator(y.mean())]\n",
    "        prev_pred = self.models_[0].predict(X).reshape(y.shape)\n",
    "        self.gammas_ = [1]\n",
    "        \n",
    "        for i in range(self.M):\n",
    "            ri = y - prev_pred\n",
    "            \n",
    "            if visualize:\n",
    "                ax[i, 1].scatter(X, ri)\n",
    "                ax[i, 1].set_ylim(-2, 2)\n",
    "                ax[i, 1].plot([0, X.max()], [0, 0], c='k', linestyle='--')\n",
    "            \n",
    "            h = DecisionTreeRegressor(max_depth=1)\n",
    "            \n",
    "            h.fit(X, ri)\n",
    "            \n",
    "            grad = h.predict(X)\n",
    "            \n",
    "            grad = grad.reshape(y.shape)\n",
    "            \n",
    "            gamma = (ri / grad).mean()\n",
    "            self.gammas_.append(gamma)\n",
    "            \n",
    "            hmgamma = gamma * grad\n",
    "            hmgamma *= self.eta\n",
    "            \n",
    "            prev_pred += hmgamma\n",
    "            \n",
    "            if visualize:\n",
    "                ax[i, 0].scatter(X, y, s=35)\n",
    "                ax[i, 0].scatter(X, prev_pred, c='r')\n",
    "            \n",
    "            self.models_.append(h)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        prediction = self.models_[0].predict(X)\n",
    "        \n",
    "        for g, m in zip(self.gammas_[1:], self.models_[1:]):\n",
    "            unscaled_pred = m.predict(X).reshape(prediction.shape)\n",
    "            unscaled_pred *= g\n",
    "            unscaled_pred *= self.eta\n",
    "            \n",
    "            prediction += unscaled_pred\n",
    "            \n",
    "        return prediction\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        params = super(NewGradientBoost, self).get_params(deep=False)\n",
    "        \n",
    "        \n",
    "        return params\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        # R2\n",
    "        return r2_score(y, self.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки результата я использую метрику R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8617670031009741"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag = BaggingRegressor(base_estimator=DecisionTreeRegressor(),\n",
    "                       n_estimators=10, random_state=0)\n",
    "\n",
    "bag.fit(X_train, y_train)\n",
    "\n",
    "r2_score(y_test, bag.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6118926957770082"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = NewGradientBoost(M=10, eta=1)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "r2_score(y_test, gb.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оптимизация гиперпараметров моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 64}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "bag_param_grid = {\n",
    "    'n_estimators': range(1, 100)\n",
    "}\n",
    "\n",
    "bag_gs = GridSearchCV(\n",
    "    BaggingRegressor(),\n",
    "    param_grid=bag_param_grid,\n",
    "    cv=5, iid=False,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "bag_gs.fit(X_train, y_train)\n",
    "\n",
    "bag_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8950993530855859"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_optimized = BaggingRegressor(**bag_gs.best_params_)\n",
    "\n",
    "bag_optimized.fit(X_train, y_train)\n",
    "\n",
    "r2_score(y_test, bag_optimized.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'M': 41, 'eta': 0.30000000000000004}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_param_grid = {\n",
    "    'M': range(1, 100),\n",
    "    'eta': [0.1 * n for n in range(1, 10)]\n",
    "}\n",
    "\n",
    "gb_gs = GridSearchCV(\n",
    "    NewGradientBoost(),\n",
    "    param_grid=gb_param_grid,\n",
    "    cv=5, iid=False,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "gb_gs.fit(X_train, y_train)\n",
    "\n",
    "gb_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7601482069453185"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_optimized = NewGradientBoost(**gb_gs.best_params_)\n",
    "\n",
    "gb_optimized.fit(X_train, y_train)\n",
    "\n",
    "r2_score(y_test, gb_optimized.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После оптимизации гиперпараметров модели ансамблевого обучения показали результат лучше, чем до.\n",
    "\n",
    "Метод градиентного бустинга показал гораздо лучший результат после оптимизации гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
